{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b06768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "from main import NaiveBayesClassifier\n",
    "from utils import Message, tokenize \n",
    "\n",
    "from io import BytesIO      # so we can treat bytes as a file \n",
    "import requests             # to download the files, which \n",
    "import tarfile              # are in .tar.bz format \n",
    "import glob, re\n",
    "\n",
    "from typing import List\n",
    "from collections import Counter \n",
    "import random \n",
    "import os \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70809666",
   "metadata": {},
   "source": [
    "# Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f2f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenize(\"Data science is science\") == {\"data\", \"science\", \"is\"}    # test if True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db2861",
   "metadata": {},
   "source": [
    "Writing some unit tests for our model to check that it works well: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "606b2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train dataset \n",
    "messages = [Message(\"spam rules\", is_spam=True), \n",
    "            Message(\"ham rules\", is_spam=False), \n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)     # train our model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3dbdb",
   "metadata": {},
   "source": [
    "Let's check that it got the counts right: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e400f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the attributes of our model \n",
    "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}    # check the vocabulary \n",
    "assert model.spam_messages == 1 \n",
    "assert model.ham_messages == 2 \n",
    "assert model.token_spam_counts == {\"spam\": 1, \"rules\": 1}\n",
    "assert model.token_ham_counts == {\"ham\": 2, \"rules\": 1, \"hello\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3b719",
   "metadata": {},
   "source": [
    "Now, let's make a prediction. We'll also go through our Naive Bayes logic by hand, and make sure that we get the same result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe269e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350515463917525"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "probs_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5), # \"spam\" (present)\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5), # \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5), # \"rules\" (not present)\n",
    "    (0 + 0.5) / (1 + 2 * 0.5) # \"hello\" (present)\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5), # \"spam\" (present)\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5), # \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5), # \"rules\" (not present)\n",
    "    (1 + 0.5) / (2 + 2 * 0.5), # \"hello\" (present)\n",
    "]\n",
    "\n",
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))\n",
    "\n",
    "p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfeccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350515463917525"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7240a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bba24e",
   "metadata": {},
   "source": [
    "# Using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ab615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "# This is where the data will end up, in\n",
    "# /spam, /easy_ham and /hard_ham subdirectories. \n",
    "# Change this to where you want the data. \n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES: \n",
    "    # use requests to get the file contents at each URL\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    \n",
    "    # wrap the in-memory bytes so we can use them as a file.\n",
    "    fin = BytesIO(content)\n",
    "    \n",
    "    # extract all the files to the specific output dir \n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf: \n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12869c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easy_ham', 'hard_ham', 'spam']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('spam_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c496ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551\n",
      "250\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir('spam_data'): \n",
    "    print(len(os.listdir(os.path.join('spam_data', folder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd57ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2551 + 250 + 501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a765c",
   "metadata": {},
   "source": [
    "- Three folders: spam, easy_ham, and hard_ham. \n",
    "- Each folder contains many emails, each contained in a single file. \n",
    "- To keep things really simple, weâ€™ll just look at the subject lines of each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a4f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'spam_data/*/*'\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path \n",
    "for filename in glob.glob(path): \n",
    "    is_spam = 'ham' not in filename                     # determine whether this file is spam or not \n",
    "    \n",
    "    # there are some garbage characters in the emails\n",
    "    # the erorrs='ignore' skips them instead of raising an exception \n",
    "    with open(filename, errors='ignore') as email_file: \n",
    "        for line in email_file: \n",
    "            if line.startswith(\"Subject:\"): \n",
    "                subject = line.lstrip(\"Subject: \")      # remove \"Subject: \" at the left of the string\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break                                   # done with this file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead906cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "print(len(data))     # ignore 2 email having garbage characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "704c3928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2475\n",
      "825\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training data and test data\n",
    "\n",
    "random.seed(0)       # to get the same answer \n",
    "\n",
    "train_msgs, test_msgs = train_test_split(data, test_size=0.25)\n",
    "\n",
    "print(len(train_msgs))\n",
    "print(len(test_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5887b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier()\n",
    "\n",
    "model.train(train_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1093727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[686  22]\n",
      " [ 39  78]]\n"
     ]
    }
   ],
   "source": [
    "# generate some predictions and check how our model does \n",
    "spam_probs = [model.predict(msg.text) for msg in test_msgs]      # prob of is_spam \n",
    "\n",
    "# assume that spam_prob > 0.5 corresponds to spam prediction \n",
    "preds = [spam_prob > 0.5 for spam_prob in spam_probs]\n",
    "labels = [msg.is_spam for msg in test_msgs]\n",
    "\n",
    "conf_matrix = confusion_matrix(labels, preds)     # labels = [False, True] = [ham, spam]\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c90e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(conf_matrix, square=True, annot=True, fmt='d', cbar=False, \n",
    "            xticklabels=['ham', 'spam'], \n",
    "            yticklabels=['ham', 'spam'])\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68af3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.97      0.96       708\n",
      "        spam       0.78      0.67      0.72       117\n",
      "\n",
      "    accuracy                           0.93       825\n",
      "   macro avg       0.86      0.82      0.84       825\n",
      "weighted avg       0.92      0.93      0.92       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb7bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
